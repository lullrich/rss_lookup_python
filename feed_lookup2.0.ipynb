{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests_futures.sessions import FuturesSession\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.parse import urldefrag, urlparse, urljoin, urlsplit, urlunsplit\n",
    "session = FuturesSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_response(url):\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        if (res.ok):\n",
    "            print(\"Status %s\" % (res.status_code))\n",
    "            return res\n",
    "        else:\n",
    "            res.raise_for_status()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(url, e)\n",
    "\n",
    "\n",
    "def parse_content(res_object):\n",
    "    if (res_object):\n",
    "        parse_only = SoupStrainer([\"a\", \"link\", \"meta\", \"title\"])\n",
    "        s = BeautifulSoup(res_object.content, \"lxml\", parse_only=parse_only)\n",
    "        return s\n",
    "    else:\n",
    "        return False;\n",
    "\n",
    "def get_urls(parsed_html, element=\"\"):\n",
    "    if (parsed_html):\n",
    "        pattern = re.compile(u\"(rss)|([./\\+]xml$)|(xml;.*)\", flags=re.I)\n",
    "        reject_pattern = re.compile(u\"(\\/comments\\/)\", flags=re.I)\n",
    "        links = (alink.get(\"href\")\n",
    "                 for alink in parsed_html.findAll(element)\n",
    "                 if re.findall(pattern, str(alink)) \n",
    "                 and not re.findall(reject_pattern, str(alink)))\n",
    "        return links\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def parse_meta_attrs(parsed_html):\n",
    "    if (parsed_html):\n",
    "        pattern = re.compile(u\"twitter:|fb:|description|og:|keywords\", flags=re.I)\n",
    "        try:\n",
    "            metas = {attrs[\"property\"]: attrs[\"content\"] for attrs in \n",
    "                     [meta.attrs for meta in parsed_html.findAll(\"meta\") \n",
    "                      if \"property=\" in str(meta) and re.findall(pattern, str(meta))]}\n",
    "            named_metas = {attrs[\"name\"]: attrs[\"content\"] for attrs in \n",
    "                     [meta.attrs for meta in parsed_html.findAll(\"meta\") \n",
    "                      if \"name=\" in str(meta) and re.findall(pattern, str(meta))]}\n",
    "            metas.update(named_metas)\n",
    "            metas[\"title\"] = parsed_html.find(\"title\").string\n",
    "            return metas\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def check_feed_response(url):\n",
    "    if (url):\n",
    "        try:\n",
    "            res = requests.get(url)\n",
    "            if (res.ok):\n",
    "                return res.headers[\"content-type\"]\n",
    "            else:\n",
    "                res.raise_for_status()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return res.status_code\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_site_info(url):\n",
    "    site_info = {\"url\": url}\n",
    "    print(\"%s: \\nGetting response...\" % (url))\n",
    "    res = get_response(url)\n",
    "    print(\"Parsing content...\")\n",
    "    html = parse_content(res)\n",
    "    site_info[\"rss_links\"] = list(set(get_urls(html, \"link\")))\n",
    "    site_info[\"rss_links\"] = [urljoin(url, link, allow_fragments=False) for link in site_info[\"rss_links\"]]\n",
    "    site_info[\"rss_leads\"] = set(get_urls(html, \"a\"))\n",
    "    site_info[\"rss_leads\"] = (urljoin(url, link, allow_fragments=False) for link in site_info[\"rss_leads\"])\n",
    "    site_info[\"rss_leads\"] = list(set(link for link in site_info[\"rss_leads\"] if link not in site_info[\"rss_links\"]))\n",
    "    print(\"found %d RSS feed(s) and %d link(s) to possible feeds\" % \n",
    "          (len(site_info[\"rss_links\"]), len(site_info[\"rss_leads\"])))\n",
    "    site_info[\"meta\"] = parse_meta_attrs(html)\n",
    "    \n",
    "    return site_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_domain_link(url):\n",
    "    scheme, netloc = urlsplit(url)[:2]\n",
    "    link = urlunsplit((scheme, netloc,\"\", \"\", \"\"))\n",
    "    return link\n",
    "\n",
    "res = requests.get(\"https://news.google.com/news?cf=all&pz=1&ned=uk&siidp=d99c9ccef53edd7975a8b314decb9a979877&ict=ln\")\n",
    "s = BeautifulSoup(res.content,\"lxml\")\n",
    "links = [a.get(\"href\") for a in s.findAll(\"a\") if not (re.findall(u\"google\\.com\", str(a.get(\"href\"))) or not str(a.get(\"href\")).startswith(\"http\"))]\n",
    "links = pd.Series(([get_domain_link(link) for link in links]))\n",
    "links = links.drop_duplicates()\n",
    "links = links.loc[links != b'',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "links.to_csv(\"glinks.csv\", sep=\"\\t\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_list = (get_site_info(url) for url in links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.mirror.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://www.newstatesman.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "https://www.theguardian.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.walesonline.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 4 link(s) to possible feeds\n",
      "http://www.dailymail.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 2 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.bbc.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.ft.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.theguardian.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.itv.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.dailyrecord.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.nbcnews.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://www.independent.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://rudaw.net: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.littlehamptongazette.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 4 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://chronicle.gi: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.telegraph.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "'content'\n",
      "http://www.theaustralian.com.au: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.aol.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 6 link(s) to possible feeds\n",
      "http://www.bbc.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://af.reuters.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.france24.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.dawn.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "https://www.rt.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.wsj.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.aljazeera.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 3 link(s) to possible feeds\n",
      "http://aranews.net: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "https://en.wikipedia.org: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://news.sky.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://blogs.spectator.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 2 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.afr.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.express.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.jpost.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://stv.tv: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.manchestereveningnews.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.cnbc.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://fox6now.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.getreading.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://gulfnews.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "https://www.flightglobal.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.expressandstar.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.knowyourmobile.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.droid-life.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.androidpolice.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.midhurstandpetworth.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 4 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.theverge.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 3 link(s) to possible feeds\n",
      "http://www.foxsports.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 4 link(s) to possible feeds\n",
      "http://www.irishexaminer.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 5 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.drivearabia.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://news.asiaone.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.theregister.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.scmagazine.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://www.techweekeurope.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.infoworld.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.gigwise.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 5 link(s) to possible feeds\n",
      "'content'\n",
      "http://uk.reuters.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.winnipegfreepress.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.belfasttelegraph.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.dailystar.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://www.newsletter.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 6 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.thestar.com.my: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 13 link(s) to possible feeds\n",
      "http://www.independent.ie: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.nzherald.co.nz: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.cricket.com.au: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.cricbuzz.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "'content'\n",
      "http://www.wisdenindia.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.envirotech-online.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.edie.net: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 10 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.bangkokpost.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.emirates247.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://marketbusinessnews.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.ndtv.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 2 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://tecake.in: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.eurekalert.org: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 2 link(s) to possible feeds\n",
      "http://www.burytimes.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.sevenoakschronicle.co.uk: \n",
      "Getting response...\n",
      "http://www.sevenoakschronicle.co.uk 404 Client Error: Not Found for url: http://www.sevenoakschronicle.co.uk/\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.gazettelive.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.stroudnewsandjournal.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.gazetteseries.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.bristolpost.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.gizmag.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.medicalnewstoday.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.techtimes.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "https://www.sciencedaily.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "'NoneType' object has no attribute 'string'\n",
      "https://munchies.vice.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.alternet.org: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 4 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.ibtimes.com.au: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.weather.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.wunderground.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://googleonex.accuweather.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.balkaninsight.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.petrolplaza.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "https://www.property-magazine.eu: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "https://itunes.apple.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.nytimes.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "https://www.babble.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.topgear.com: \n",
      "Getting response...\n",
      "http://www.topgear.com 403 Client Error: Forbidden for url: http://www.topgear.com/\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.ibtimes.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://fivethirtyeight.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://www.bloomberg.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.rte.ie: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.firstpost.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 3 link(s) to possible feeds\n",
      "https://www.thesun.co.uk: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://news.nationalpost.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.indiatimes.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 0 RSS feed(s) and 0 link(s) to possible feeds\n",
      "http://www.cbc.ca: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://abcnews.go.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 1 link(s) to possible feeds\n",
      "http://googlenewsblog.blogspot.com: \n",
      "Getting response...\n",
      "Status 200\n",
      "Parsing content...\n",
      "found 1 RSS feed(s) and 0 link(s) to possible feeds\n",
      "CPU times: user 19.7 s, sys: 288 ms, total: 20 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%time dicts = list(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "rss_links = filter(None, map(lambda x: x[\"rss_links\"], dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_rss_links = list(chain.from_iterable(rss_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = urls[10:20].copy()\n",
    "df[\"content\"] = df[\"url\"].apply(get_response).apply(parse_content)\n",
    "df[\"links\"] = df[\"content\"].apply(get_urls, element = \"link\").apply(list)\n",
    "df[\"leads\"] = df[\"content\"].apply(get_urls, element = \"a\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = df.apply(lambda x: pd.Series(x['links']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "f.name = 'links'\n",
    "df = df.drop('links', axis=1).join(f)\n",
    "f = df.apply(lambda x: pd.Series(x['leads']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "f.name = 'leads'\n",
    "df = df.drop('leads', axis=1).join(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.fillna(\"\")\n",
    "df[\"url\"] = df[\"url\"].str.rstrip(\"/\")\n",
    "df[\"links\"] = df[\"links\"].str.rstrip(\"/\")\n",
    "df[\"leads\"] = df[\"leads\"].str.rstrip(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"links\"] = df.apply(lambda x: urljoin(x[\"url\"], str(x[\"links\"])), axis=1)\n",
    "df[\"leads\"] = df.apply(lambda x: urljoin(x[\"url\"], str(x[\"leads\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"link_type\"] = df[\"links\"].apply(check_feed_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", sep=\"\\t\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"test\"] = df[\"links\"] != df[\"leads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"og\"] = df[\"content\"].apply(parse_opengraph_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
